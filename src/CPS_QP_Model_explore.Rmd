---
title: "CPS_QP_Clean"
author: "Sam Neylon"
date: "July 21, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#### Using "here" to keep project directory as working directory
#### NOTE: Rmarkdown will try to make the file it is inside the working directory, but "here" should fix it.

library(here)
library(tidyverse)
library(data.table)
library(DBI)
library(Hmisc)
library(pacman)
library(ggplot2)
library(plm)

library(ggeffects)
library(interplot)

```

# Weighted Quantile Function

Apparently the Hmisc package is broken, when it comes to weighted quantiles - so this angry guy fixed it: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-661793822

Here is his code:

```{r eval=TRUE}

wtd.quantile<- function (x, weights = NULL, probs = c(0, 0.25, 0.5, 0.75, 1),
                         type = c("quantile", "(i-1)/(n-1)", "i/(n+1)", "i/n"),
                         na.rm = TRUE)  {
  # Function taken from HMISC, but issue solved which is documented here: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-429634634
  normwt = FALSE
  if (!length(weights))      return(quantile(x, probs = probs, na.rm = na.rm))
  type <- match.arg(type)
  if (any(probs < 0 | probs > 1))      stop("Probabilities must be between 0 and 1 inclusive")
  nams <- paste(format(round(probs * 100, if (length(probs) >
                                              1) 2 - log10(diff(range(probs))) else 2)), "%", sep = "")

  if(na.rm & any(is.na(weights))){   ###### new
    i<- is.na(weights)
    x <- x[!i]
    weights <- weights[!i]
  }
  i <- weights <= 0         # nwe: kill negative and zero weights and associated data
  if (any(i)) {
    x <- x[!i]
    weights <- weights[!i]
  }
  if (type == "quantile") {
    if(sum(weights) < 1000000 ) {weights<- weights*1000000/sum(weights)}  ##### new
    w <- wtd.table(x, weights, na.rm = na.rm, normwt = normwt,
                   type = "list")
    x <- w$x
    wts <- w$sum.of.weights
    n <- sum(wts)
    order <- 1 + (n - 1) * probs
    low <- pmax(floor(order), 1)
    high <- pmin(low + 1, n)
    order <- order%%1
    allq <- approx(cumsum(wts), x, xout = c(low, high), method = "constant",
                   f = 1, rule = 2)$y
    k <- length(probs)
    quantiles <- (1 - order) * allq[1:k] + order * allq[-(1:k)]
    names(quantiles) <- nams
    return(quantiles)
  }
  w <- wtd.Ecdf(x, weights, na.rm = na.rm, type = type, normwt = normwt)
  structure(approx(w$ecdf, w$x, xout = probs, rule = 2)$y,
            names = nams)
}




wtd.table<- function (x, weights = NULL, type = c("list", "table"), normwt = FALSE,
                      na.rm = TRUE) {
  # Function taken from HMISC, but issue solved which is documented here: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-429634634
  p_load(timeDate)
  type <- match.arg(type)
  if (!length(weights))
    weights <- rep(1, length(x))
  isdate <- ( class(x)[1]=="Date"  | class(x)[1]=="POSIXct") ### MODIFIED
  ax <- attributes(x)
  ax$names <- NULL
  if (is.character(x))
    x <- as.factor(x)
  lev <- levels(x)
  x <- unclass(x)
  if (na.rm) {
    s <- !is.na(x + weights)
    x <- x[s, drop = FALSE]
    weights <- weights[s]
  }
  n <- length(x)
  if (normwt)
    weights <- weights * length(x)/sum(weights)
  i <- order(x)
  x <- x[i]
  weights <- weights[i]
  if (anyDuplicated(x)) {
    weights <- tapply(weights, x, sum)
    if (length(lev)) {
      levused <- lev[sort(unique(x))]
      if ((length(weights) > length(levused)) && any(is.na(weights)))
        weights <- weights[!is.na(weights)]
      if (length(weights) != length(levused))
        stop("program logic error")
      names(weights) <- levused
    }
    if (!length(names(weights)))
      stop("program logic error")
    if (type == "table")
      return(weights)
    #x <-  all.is.numeric(names(weights), "vector")#  modified: commented out. function checked whether all are numeric and if yes returned the weights
    if (isdate)      attributes(x) <- c(attributes(x), ax)
    x_out<- as.numeric(names(weights))
    names(weights) <- NULL
    return(list(x = x_out, sum.of.weights = weights))
  }
  xx <- x
  if (isdate)
    attributes(xx) <- c(attributes(xx), ax)
  if (type == "list")
    list(x = if (length(lev)) lev[x] else xx, sum.of.weights = weights)
  else {
    names(weights) <- if (length(lev))
      lev[x]
    else xx
    weights
  }
}

wtd.mean <- function (x, weights = NULL, normwt = "ignored", na.rm = TRUE) {
  # Function taken from HMISC, but issue solved which is documented here: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-429634634
  if (!length(weights))
    return(mean(x, na.rm = na.rm))
  if (na.rm) {
    s <- !is.na(x + weights)
    x <- x[s]
    weights <- weights[s]
  }
  sum(weights * x)/sum(weights)
}


```

# FIX interplot

interplot doesn't play nice with plm, but this dude apparently fixed it: https://github.com/sammo3182/interplot/issues/26#issuecomment-457272328

```{r eval=TRUE}

#rm(list = ls())


library(plm)
library(interplot)






#############################
### Define interplot.plot ###
#############################


## S3 method for class 'data.frame'
interplot.plot <- function(m, var1 = NULL, var2 = NULL, plot = TRUE, steps = NULL, ci = .95, hist = FALSE, var2_dt = NULL, point = FALSE, sims = 5000, xmin = NA, xmax = NA, ercolor = NA, esize = 0.5, ralpha = 0.5, rfill = "grey70", ...) {
  if(is.null(steps)) steps <- nrow(m)
  levels <- sort(unique(m$fake))
  ymin <- ymax <- vector() # to deal with the "no visible binding for global variable" issue
  xdiff <- vector() # to deal with the "no visible binding for global variable" issue
  
  
  if (hist == FALSE) {
    if (steps < 10 | point == T) {
      if (is.na(ercolor)) 
      {
        ercolor <- "black"
      }  # ensure whisker can be drawn
      coef.plot <- ggplot(m, aes_string(x = "fake", y = "coef1")) + geom_point(...) + geom_errorbar(aes_string(ymin = "lb", 
                                                                                                               ymax = "ub"), width = 0, color = ercolor, size = esize) + scale_x_continuous(breaks = levels) + 
        ylab(NULL) + xlab(NULL)
    } else {
      coef.plot <- ggplot(m, aes_string(x = "fake", y = "coef1")) + geom_line(...) + geom_ribbon(aes_string(ymin = "lb", 
                                                                                                            ymax = "ub"), alpha = ralpha, color = ercolor, fill = rfill) + ylab(NULL) + xlab(NULL)
    }
    return(coef.plot)
  } else {
    if (point == T) {
      if (is.na(ercolor)) 
      {
        ercolor <- "black"
      }  # ensure whisker can be drawn
      
      yrange <- c(m$ub, m$lb, var2_dt)
      maxdiff <- (max(yrange) - min(yrange))
      
      break_var2 <- steps + 1
      if (break_var2 >= 100) 
        break_var2 <- 100
      hist.out <- hist(var2_dt, breaks = seq(min(var2_dt), max(var2_dt), l = break_var2), plot = FALSE)
      
      n.hist <- length(hist.out$mids)
      
      if (steps <10) {dist <- (hist.out$mids[2] - hist.out$mids[1])/3
      } else {dist <- hist.out$mids[2] - hist.out$mids[1]}
      hist.max <- max(hist.out$counts)
      
      if (steps <10) {
        histX <- data.frame(ymin = rep(min(yrange) - maxdiff/5, n.hist),
                            ymax = hist.out$counts/hist.max * maxdiff/5 + min(yrange) - maxdiff/5, 
                            xmin = sort(unique(var2_dt)) - dist/2, 
                            xmax = sort(unique(var2_dt)) + dist/2)
      } else {
        histX <- data.frame(ymin = rep(min(yrange) - maxdiff/5, n.hist), 
                            ymax = hist.out$counts/hist.max * maxdiff/5 + min(yrange) - maxdiff/5, 
                            xmin = hist.out$mids - dist/2, 
                            xmax = hist.out$mids + dist/2)
      } 
      #when up to 10, the sort(unique(var2_dt)) - dist/2 leads to problemtic histogram
      
      
      if (steps <10) {
        histX_sub <- histX
      } else {
        histX_sub <- mutate(histX, xdiff = xmax - xmin, xmax = xmax - xdiff/2)
      }
      
      coef.plot <- ggplot()
      coef.plot <- coef.plot + geom_rect(data = histX, aes(xmin = xmin, xmax = xmax, ymin = ymin, 
                                                           ymax = ymax), colour = "gray50", alpha = 0, size = 0.5)  #histgram
      
      coef.plot <- coef.plot +
        geom_errorbar(data = m, aes_string(x = "fake", ymin = "lb", ymax = "ub"), width = 0, 
                      color = ercolor, size = esize) + scale_x_continuous(breaks = levels) + ylab(NULL) + 
        xlab(NULL) + geom_point(data = m, aes_string(x = "fake", y = "coef1")) 
      
    } else {
      
      yrange <- c(m$ub, m$lb)
      
      maxdiff <- (max(yrange) - min(yrange))
      
      break_var2 <- length(unique(var2_dt))
      if (break_var2 >= 100) 
        break_var2 <- 100
      hist.out <- hist(var2_dt, breaks = break_var2, plot = FALSE)
      
      n.hist <- length(hist.out$mids)
      dist <- hist.out$mids[2] - hist.out$mids[1]
      hist.max <- max(hist.out$counts)
      
      histX <- data.frame(ymin = rep(min(yrange) - maxdiff/5, n.hist), ymax = hist.out$counts/hist.max * 
                            maxdiff/5 + min(yrange) - maxdiff/5, xmin = hist.out$mids - dist/2, xmax = hist.out$mids + 
                            dist/2)
      
      
      
      # interplot.plot(m = coef, var1 = 'cyl', var2 = 'wt')
      
      coef.plot <- ggplot()
      coef.plot <- coef.plot + geom_rect(data = histX, aes(xmin = xmin, xmax = xmax, ymin = ymin, 
                                                           ymax = ymax), colour = "gray50", alpha = 0, size = 0.5)
      
      
      coef.plot <- coef.plot + geom_line(data = m, aes_string(x = "fake", y = "coef1")) + 
        geom_ribbon(data = m, aes_string(x = "fake", ymin = "lb", ymax = "ub"), alpha = ralpha, 
                    color = ercolor, fill = rfill) + ylab(NULL) + xlab(NULL)
    }
    return(coef.plot)
  }
  
} 



#################################
#### Set sims method for plm ####
#################################

sim.plm<-function(object, n.sims=100)
{
  object.class <- class(object)[[1]]
  summ <- summary (object)
  coef <- summ$coef[,1:2,drop=FALSE]
  dimnames(coef)[[2]] <- c("coef.est","coef.sd")
  # sigma.hat <- summ$sigma 
  # TR: define sigma by hand
  NN <- nrow(object$model)
  PP <- nrow(coef)
  sigma.hat <- sqrt(deviance(object) / (NN-PP))
  # TR: end              
  beta.hat <- coef[,1,drop = FALSE]
  # V.beta <- summ$vcov # TR: Use scaled vcov
  # V.beta <- summ$cov.unscaled
  V.beta <- vcov(summ)/sigma.hat^2 # TR: unscale scaled vcov
  # n <- summ$df[1] + summ$df[2]
  # k <- summ$df[1]
  n <- nrow(summ$model) # TR: define n
  k <- nrow(summ$coefficients) # TR: define k
  sigma <- rep (NA, n.sims)
  beta <- array (NA, c(n.sims,k))
  dimnames(beta) <- list (NULL, rownames(beta.hat))
  for (s in 1:n.sims){
    sigma[s] <- sigma.hat*sqrt((n-k)/rchisq(1,n-k))
    # beta[s,] <- MASS::mvrnorm (1, beta.hat, V.beta) # TR: if above: vcov (scaled) than without "*sigma[s]^2"
    beta[s,] <- MASS::mvrnorm(1, beta.hat, V.beta * sigma[s]^2)
  }
  
  ans <- new("sim",
             coef = beta,
             sigma = sigma)
  return (ans)
}
setMethod("sim", signature = "plm",
          definition = sim.plm)




# ### Old way ###
# 
# sim.plm<-function(object, n.sims=100)
# {
#   object.class <- class(object)[[1]]
#   summ <- summary (object)
#   coef <- summ$coef[,1:2,drop=FALSE]
#   dimnames(coef)[[2]] <- c("coef.est","coef.sd")
#   # sigma.hat <- summ$sigma 
#   # TR: define sigma by hand
#   NN <- nrow(object$model)
#   PP <- length(coef)
#   sigma.hat <- sqrt(deviance(object) / (NN-PP))
#   # TR: end              
#   beta.hat <- coef[,1,drop = FALSE]
#   V.beta <- summ$vcov
#   # V.beta <- summ$cov.unscaled
#   n <- nrow(summ$model)
#   k <- nrow(summ$coefficients)
#   # n <- summ$df[1] + summ$df[2]
#   # k <- summ$df[1]
#   sigma <- rep (NA, n.sims)
#   beta <- array (NA, c(n.sims,k))
#   dimnames(beta) <- list (NULL, rownames(beta.hat))
#   for (s in 1:n.sims){
#     sigma[s] <- sigma.hat*sqrt((n-k)/rchisq(1,n-k))
#     beta[s,] <- MASS::mvrnorm (1, beta.hat, V.beta) # oben vcov (scaled) hier "*sigma[s]^2" raus
#     # beta[s,] <- MASS::mvrnorm(1, beta.hat, V.beta * sigma[s]^2)
#   }
#   
#   ans <- new("sim",
#              coef = beta,
#              sigma = sigma)
#   return (ans)
# }
# setMethod("sim", signature = "plm",
#           definition = sim.plm)






#####################
### Interplot plm ###
#####################

interplot.plm <- function(m, var1, var2, plot = TRUE, steps = NULL, 
                              ci = .95, hist = FALSE, var2_dt = NA, point = FALSE, sims = 5000, xmin = NA, 
                              xmax = NA, ercolor = NA, esize = 0.5, ralpha = 0.5, rfill = "grey70", 
                              ...) {
  set.seed(324)
  
  m.class <- class(m)
  m.sims <- arm::sim(m, sims)
  
  
  ### For factor base terms###
  factor_v1 <- factor_v2 <- FALSE
  
  if (is.factor(eval(parse(text = paste0("m$model$", var1)))) & is.factor(eval(parse(text = paste0("m$model$", 
                                                                                                   var2))))) 
    stop("The function does not support interactions between two factors.")
  
  
  if (is.factor(eval(parse(text = paste0("m$model$", var1))))) {
    var1_bk <- var1
    var1 <- paste0(var1, eval(parse(text = paste0("m$xlevel$", var1))))
    factor_v1 <- TRUE
    ifelse(var1 == var2, var12 <- paste0("I(", var1, "^2)"), var12 <- paste0(var2, 
                                                                             ":", var1)[-1])
    
    # the first category is censored to avoid multicolinarity
    for (i in seq(var12)) {
      if (!var12[i] %in% names(m$coef)) 
        var12[i] <- paste0(var1, ":", var2)[-1][i]
      if (!var12[i] %in% names(m$coef)) 
        stop(paste("Model does not include the interaction of", 
                   var1, "and", var2, "."))
    }
    
  } else if (is.factor(eval(parse(text = paste0("m$model$", var2))))) {
    var2_bk <- var2
    var2 <- paste0(var2, eval(parse(text = paste0("m$xlevel$", var2))))
    factor_v2 <- TRUE
    ifelse(var1 == var2, var12 <- paste0("I(", var1, "^2)"), var12 <- paste0(var2, 
                                                                             ":", var1)[-1])
    
    # the first category is censored to avoid multicolinarity
    for (i in seq(var12)) {
      if (!var12[i] %in% names(m$coef)) 
        var12[i] <- paste0(var1, ":", var2)[-1][i]
      if (!var12[i] %in% names(m$coef)) 
        stop(paste("Model does not include the interaction of", 
                   var1, "and", var2, "."))
    }
    
  } else {
    ifelse(var1 == var2, var12 <- paste0("I(", var1, "^2)"), var12 <- paste0(var2, 
                                                                             ":", var1))
    
    # the first category is censored to avoid multicolinarity
    for (i in seq(var12)) {
      if (!var12[i] %in% names(m$coef)) 
        var12[i] <- paste0(var1, ":", var2)[i]
      if (!var12[i] %in% names(m$coef)) 
        stop(paste("Model does not include the interaction of", 
                   var1, "and", var2, "."))
    }
  }
  
  ################### 
  
  
  if (factor_v2) {
    xmin <- 0
    xmax <- 1
    steps <- 2
  } else {
    if (is.na(xmin)) 
      #xmin <- min(m$model[var2], na.rm = T) 
      xmin <- min(m$model[, which(names(m$model)==var2)], na.rm = T) # TR
    if (is.na(xmax)) 
      #xmax <- max(m$model[var2], na.rm = T)
      xmax <- max(m$model[, which(names(m$model)==var2)], na.rm = T) # TR
    
    if (is.null(steps)) {
      steps <- eval(parse(text = paste0("length(unique(na.omit(m$model$", 
                                        var2, ")))")))
    }
    
    
    if (steps > 100) 
      steps <- 100  # avoid redundant calculation
  }
  
  coef <- data.frame(fake = seq(xmin, xmax, length.out = steps), coef1 = NA, 
                     ub = NA, lb = NA)
  coef_df <- data.frame(fake = numeric(0), coef1 = numeric(0), ub = numeric(0), 
                        lb = numeric(0), model = character(0))
  
  if (factor_v1) {
    for (j in 1:(length(eval(parse(text = paste0("m$xlevel$", var1_bk)))) - 
                 1)) {
      # only n - 1 interactions; one category is avoided against
      # multicolinarity
      
      for (i in 1:steps) {
        coef$coef1[i] <- mean(m.sims@coef[, match(var1[j + 1], 
                                                  names(m$coef))] + coef$fake[i] * m.sims@coef[, match(var12[j], 
                                                                                                       names(m$coef))])
        coef$ub[i] <- quantile(m.sims@coef[, match(var1[j + 1], 
                                                   names(m$coef))] + coef$fake[i] * m.sims@coef[, match(var12[j], 
                                                                                                        names(m$coef))], 1 - (1 - ci) / 2)
        coef$lb[i] <- quantile(m.sims@coef[, match(var1[j + 1], 
                                                   names(m$coef))] + coef$fake[i] * m.sims@coef[, match(var12[j], 
                                                                                                        names(m$coef))], (1 - ci) / 2)
      }
      
      if (plot == TRUE) {
        coef$value <- var1[j + 1]
        coef_df <- rbind(coef_df, coef)
        if (hist == TRUE) {
          if (is.na(var2_dt)) {
            var2_dt <- eval(parse(text = paste0("m$model$", var2)))
          } else {
            var2_dt <- var2_dt
          }
        }
      } else {
        names(coef) <- c(var2, "coef", "ub", "lb")
        return(coef)
      }
    }
    coef_df$value <- as.factor(coef_df$value)
    interplot.plot(m = coef_df, hist = hist, var2_dt = var2_dt, steps = steps, 
                   point = point, ercolor = ercolor, esize = esize, ralpha = ralpha, 
                   rfill = rfill, ...) + facet_grid(. ~ value)
    
  } else if (factor_v2) {
    for (j in 1:(length(eval(parse(text = paste0("m$xlevel$", var2_bk)))) - 
                 1)) {
      # only n - 1 interactions; one category is avoided against
      # multicolinarity
      
      for (i in 1:steps) {
        coef$coef1[i] <- mean(m.sims@coef[, match(var1, names(m$coef))] + 
                                coef$fake[i] * m.sims@coef[, match(var12[j], names(m$coef))])
        coef$ub[i] <- quantile(m.sims@coef[, match(var1, names(m$coef))] + 
                                 coef$fake[i] * m.sims@coef[, match(var12[j], names(m$coef))], 
                               1 - (1 - ci) / 2)
        coef$lb[i] <- quantile(m.sims@coef[, match(var1, names(m$coef))] + 
                                 coef$fake[i] * m.sims@coef[, match(var12[j], names(m$coef))], 
                               (1 - ci) / 2)
      }
      
      if (plot == TRUE) {
        coef$value <- var2[j + 1]
        coef_df <- rbind(coef_df, coef)
        if (hist == TRUE) {
          if (is.na(var2_dt)) {
            var2_dt <- eval(parse(text = paste0("m$model$", var2)))
          } else {
            var2_dt <- var2_dt
          }
        }
      } else {
        names(coef) <- c(var2, "coef", "ub", "lb")
        return(coef)
      }
    }
    coef_df$value <- as.factor(coef_df$value)
    interplot.plot(m = coef_df, hist = hist, steps = steps, var2_dt = var2_dt, 
                   point = point, ercolor = ercolor, esize = esize, ralpha = ralpha, 
                   rfill = rfill, ...) + facet_grid(. ~ value)
    
    
  } else {
    ## Correct marginal effect for quadratic terms
    multiplier <- if (var1 == var2) 
      2 else 1
    
    for (i in 1:steps) {
      coef$coef1[i] <- mean(m.sims@coef[, match(var1, names(m$coef))] + 
                              multiplier * coef$fake[i] * m.sims@coef[, match(var12, 
                                                                              names(m$coef))])
      coef$ub[i] <- quantile(m.sims@coef[, match(var1, names(m$coef))] + 
                               multiplier * coef$fake[i] * m.sims@coef[, match(var12, 
                                                                               names(m$coef))], 1 - (1 - ci) / 2)
      coef$lb[i] <- quantile(m.sims@coef[, match(var1, names(m$coef))] + 
                               multiplier * coef$fake[i] * m.sims@coef[, match(var12, 
                                                                               names(m$coef))], (1 - ci) / 2)
    }
    
    if (plot == TRUE) {
      if (hist == TRUE) {
        if (is.na(var2_dt)) {
          var2_dt <- eval(parse(text = paste0("m$model$", var2)))
        } else {
          var2_dt <- var2_dt
        }
      }
      interplot.plot(m = coef, steps = steps, hist = hist, var2_dt = var2_dt, 
                     point = point, ercolor = ercolor, esize = esize, ralpha = ralpha, 
                     rfill = rfill, ...)
    } else {
      names(coef) <- c(var2, "coef", "ub", "lb")
      return(coef)
    }
    
  }
  
}






# ###############
# ### Example ###
# ###############
# 
# 
# data(Cigar)
# 
# 
# 
# ### models ###
# 
# plm.mod<-plm(sales~ price + pop + pimin + price*pimin,
#              model="within", effect="individual",
#              index=c("state", "year"), data=Cigar)
# summary(plm.mod)
# 
# 
# lm.mod<-lm(sales~ price + pop + pimin + price*pimin,
#            data=Cigar)
# summary(lm.mod)
# 
# 
# 
# ### Interplot lm ###
# 
# lm.intpl<-interplot(lm.mod, "price", "pimin")
# 
# 
# lm.intpl
# 
# 
# ### Interplot plm ###
# 
# plm.intpl<-interplot.plm(plm.mod, "price", "pimin", plot=T)
# 
# plm.intpl

```

# CPS Cleaning

(Taken from "CPS_QP_Clean.Rmd")

## Notes on SQLite

Because the data file is so large, I decided to access it as an SQLite database, instead of loading it into memory.

Information on this is below.

*NOTE: In the future, when I understand SQL, I should rewrite the code, as I could more easily extract just the outgoing groups (which requires loading the database with "integer" columns) in SQL, and leave other stuff to R. For now, I will be doing it in dplyr.

## RSQLite Code

```{r eval=TRUE}

# This code establishes a connection with my database
# See: https://data.library.virginia.edu/creating-a-sqlite-database-for-use-with-r/

con <- dbConnect(RSQLite::SQLite(), here("data/IPUMS_CPS/cps_master.db"))

# This allows dplyr to use the connection like an object:

cpsALL <- tbl(con, "cpsALL")

```

# Disconnect SQLite

Run this code to disconnect from the database

```{r eval=FALSE}

dbDisconnect(con)

```


### Quantiles - 90/10

Seems like Kristal 2017 uses 90/10 ratio as measure of inequality

WARNING: EPI argue that you need to bin before using quantiles, since wages clump at certain values: https://www.epi.org/data/methodology/ (see "Wage Percentiles" section)

```{r eval=FALSE}

# Create ORG Microdata

# list of variables:

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0),
         manager = if_else(OCC2010 >= 10 & OCC2010 <= 430, 1, 0),
         HOURWAGE2 = if_else(HOURWAGE != 999.99, HOURWAGE, NA_integer_),
         UHRSWORK1_2 = if_else(UHRSWORK1 == 999 | UHRSWORK1 == 997 | UHRSWORK1 == 0, NA_integer_, UHRSWORK1),
         hrWAGE2 = if_else(PAIDHOUR == 2, HOURWAGE2,
                           if_else(PAIDHOUR == 1, (EARNWEEK / UHRSWORK1_2), NA_integer_)),
         mgmtWAGE = if_else(manager == 1, hrWAGE2, NA_integer_),
         NONmgmtWAGE = if_else(manager == 0, hrWAGE2, NA_integer_),
         ln_hrWAGE2 = log(hrWAGE2),
         ln_mgmtWAGE = log(mgmtWAGE),
         ln_NONmgmtWAGE = log(NONmgmtWAGE)
         ) %>% 
  select(ELIGORG, YEAR, unionMEM, manager, HOURWAGE2, UHRSWORK1_2, hrWAGE2, PAIDHOUR, IND1990, OCC2010, EARNWT, mgmtWAGE, NONmgmtWAGE, ln_hrWAGE2, ln_mgmtWAGE, ln_NONmgmtWAGE) %>% 
  collect()

## view(head(cpsORG, 300))


# Another way to check:

## cpsCHECK <- slice_sample(cpsORG, n = 100) %>% collect()

# Checking on the WKSWORKORG variable - since my "head" has a lot of "1" weeks worked...

## wksCOUNT <- cpsORG %>% count(WKSWORKORG) %>% collect()

# NOTE: Looks like it's all good - most people either work 52 weeks a year, or are 0 (not in universe)
  

# Create Industry Panel

cpsDATA <- group_by(cpsORG, IND1990, YEAR)

cpsDATA <- summarise(cpsDATA, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12),
                     mgmtEMP = (sum(EARNWT * manager, na.rm = TRUE)/12), 
                     avgWAGE = weighted.mean(hrWAGE2, EARNWT, na.rm = TRUE),
                     NONmgmtAVG = weighted.mean(NONmgmtWAGE, EARNWT, na.rm = TRUE),
                     mgmtAVG = weighted.mean(mgmtWAGE, EARNWT, na.rm = TRUE),
                     ln_avgWAGE = weighted.mean(ln_hrWAGE2, EARNWT, na.rm = TRUE),
                     ln_NONmgmtAVG = weighted.mean(ln_NONmgmtWAGE, EARNWT, na.rm = TRUE),
                     ln_mgmtAVG = weighted.mean(ln_mgmtWAGE, EARNWT, na.rm = TRUE),
                     var_wages = wtd.var(ln_hrWAGE2, EARNWT, na.rm = TRUE),
                     Wage90 = wtd.quantile(hrWAGE2, EARNWT, probs = .9, na.rm = TRUE),
                     Wage10 = wtd.quantile(hrWAGE2, EARNWT, probs = .1, na.rm = TRUE))

# Drop big ole data set

rm(cpsORG)

# Create New Variables

cpsDATA <- ungroup(cpsDATA)

cpsDATA <- cpsDATA %>% 
  mutate(pctUNION = (unionEMP / TotEMP)*100,
         mgmtRATIO = (mgmtEMP / TotEMP)*100,
         ratio90_10 = (Wage90 / Wage10),
         log90_10 = log(Wage90 / Wage10))

```

## Notes

Things seem to be working okay? Go back over everything.

Next, I think you can start running models?

# (07-26-2021)

I have moved over the code needed to set up my data from "CPS_QP_clean.Rmd", and am using this document to explore modelling.

I am using my models from the CES project as a guide, but this time I am looking (like Kristal et al.) at *inequality* - specifically, the log of the 90 10 ratio and the variance of log wages (per Kristal 2015 pg 36)

- I also want to do an error correction model (like Kristal), but haven't figured that out yet

Strategy of Analysis:

- fixed effects (plm)
- Year (pure time trend) *note* I can't figure out how to do this in plm - so maybe I should ask someone later or something
- Effect of management ratio on inequality
- Effect of union ratio on inequality
- Effect of both union and management
- Effect of union and management interaction
  - Must do marginal analysis
  
## P_series

Put data in industry-year panel format for plm()

```{r eval=FALSE}

P_series <- pdata.frame(cpsDATA, index = c("IND1990","YEAR"), drop.index=T, row.names = T)

```

## plm models

### 90_10

- Effect of management ratio on inequality
- Effect of union ratio on inequality
- Effect of both union and management

```{r eval=FALSE}

ln9010.mgmt <- plm(log90_10 ~ mgmtRATIO, data = P_series, model = "within")

ln9010.union <- plm(log90_10 ~ pctUNION, data = P_series, model = "within")

ln9010.mgmt_union <- plm(log90_10 ~ mgmtRATIO + pctUNION, data = P_series, model = "within")

```


```{r eval=FALSE}

summary(ln9010.mgmt)

```


```{r eval=FALSE}

summary(ln9010.union)

```


```{r eval=FALSE}

summary(ln9010.mgmt_union)

```

### variance


```{r eval=FALSE}

var.mgmt <- plm(var_wages ~ mgmtRATIO, data = P_series, model = "within")

var.union <- plm(var_wages ~ pctUNION, data = P_series, model = "within")

var.mgmt_union <- plm(var_wages ~ mgmtRATIO + pctUNION, data = P_series, model = "within")

```


```{r eval=FALSE}

summary(var.mgmt)

```


```{r eval=FALSE}

summary(var.union)

```


```{r eval=FALSE}

summary(var.mgmt_union)

```

## Marginal Analysis

Run interaction, and then plot margins per the ICPSR lab 5 - "2021.1 Spring/ICPSR MLM Workshop"

```{r eval=FALSE}

ln9010.mgmtXunion <- plm(log90_10 ~ mgmtRATIO * pctUNION, data = P_series, model = "within")

var.mgmtXunion <- plm(var_wages ~ mgmtRATIO * pctUNION, data = P_series, model = "within")

```

### log 90-10

From Lab 5: "2021.1 Spring/ICPSR MLM Workshop"

```{r eval=FALSE}

ln9010.margins <- interplot(m = ln9010.mgmtXunion, var1 = "mgmtRATIO", var2 = "pctUNION", ercolor= "gray")+
geom_line()+
theme_minimal()+
theme(axis.text=element_text(size=16), 
      axis.title.x = element_text(size=16),
      axis.title.y = element_text(size=16, color="red",face="bold.italic"))+
ylab("Marginal Effects of Mgmt Ratio")+
xlab("Pct Union")+
geom_hline(yintercept=0, linetype="dotted", lwd=0.5)+
ggtitle("DV=log 90-10 Wage Inequality")+
labs(caption="")
ln9010.margins
```

### wage variance (variance of log wages)

From Lab 5: "2021.1 Spring/ICPSR MLM Workshop"

```{r eval=FALSE}

var.margins <- interplot(m = var.mgmtXunion, var1 = "mgmtRATIO", var2 = "pctUNION", ercolor= "gray")+
geom_line()+
theme_minimal()+
theme(axis.text=element_text(size=16), 
      axis.title.x = element_text(size=16),
      axis.title.y = element_text(size=16, color="red",face="bold.italic"))+
ylab("Marginal Effects of Mgmt Ratio")+
xlab("Pct Union")+
geom_hline(yintercept=0, linetype="dotted", lwd=0.5)+
ggtitle("DV=Variance of Log Wages")+
labs(caption="")
var.margins
```

### reverse 90-10

With unions this time

```{r eval=FALSE}

ln9010.margins.rev <- interplot(m = ln9010.mgmtXunion, var1 = "pctUNION", var2 = "mgmtRATIO", ercolor= "gray")+
geom_line()+
theme_minimal()+
theme(axis.text=element_text(size=16), 
      axis.title.x = element_text(size=16),
      axis.title.y = element_text(size=16, color="red",face="bold.italic"))+
ylab("Marginal Effects of Pct Union")+
xlab("Mgmt Ratio")+
geom_hline(yintercept=0, linetype="dotted", lwd=0.5)+
ggtitle("DV=log 90-10 Wage Inequality")+
labs(caption="")
ln9010.margins.rev
```

### reverse wage variance (variance of log wages)

with unions this time

```{r eval=FALSE}

var.margins.rev <- interplot(m = var.mgmtXunion, var1 = "pctUNION", var2 = "mgmtRATIO", ercolor= "gray")+
geom_line()+
theme_minimal()+
theme(axis.text=element_text(size=16), 
      axis.title.x = element_text(size=16),
      axis.title.y = element_text(size=16, color="red",face="bold.italic"))+
ylab("Marginal Effects of Pct Union")+
xlab("Mgmt Ratio")+
geom_hline(yintercept=0, linetype="dotted", lwd=0.5)+
ggtitle("DV=Variance of Log Wages")+
labs(caption="")
var.margins.rev
```

## Error Correction Model

I'm just going to straight up use the one from Lab 5: "2021.1 Spring/ICPSR MLM Workshop"

*NOTE* This might not be the right design for me... but let's just try it!

```{r ecm}
ECM<-lm(dgap~lgap+limmigration+dimmigration+eligibility2+
          limmigration*eligibility2+dimmigration*eligibility2
          +diversity+union+unemp+poverty+lib+
          govideo+totdempct+dgovernor+south,data=Mydata2)
summary(ECM)
```

List of variables needed:

- Dependent
  - first difference (this is the DV)
  - lag (as IV)
NOTE!! - looking at lab 5 notes, this is a bit confusing, as "eligibility" doesn't have lags or anything - I need to look at her actual paper, but I am getting tired
  - I took a look, and this is because they believe that immigrant population and medicaid inequality are related (people move to states with better conditions for immigrants), so that is why they add lags etc. to just those
  - Since I believe that it is union and mgmt that are related (not necessarily wage inequality) I need to figure out how to Error Correct or whatever those

