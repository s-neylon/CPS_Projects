---
title: "CPS_QP_Clean"
author: "Sam Neylon"
date: "July 21, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#### Using "here" to keep project directory as working directory
#### NOTE: Rmarkdown will try to make the file it is inside the working directory, but "here" should fix it.

library(here)
library(tidyverse)
library(data.table)
library(DBI)
library(Hmisc)
library(pacman)

```

# Weighted Quantile Function

Apparently the Hmisc package is broken, when it comes to weighted quantiles - so this angry guy fixed it: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-661793822

Here is his code:

```{r}

wtd.quantile<- function (x, weights = NULL, probs = c(0, 0.25, 0.5, 0.75, 1),
                         type = c("quantile", "(i-1)/(n-1)", "i/(n+1)", "i/n"),
                         na.rm = TRUE)  {
  # Function taken from HMISC, but issue solved which is documented here: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-429634634
  normwt = FALSE
  if (!length(weights))      return(quantile(x, probs = probs, na.rm = na.rm))
  type <- match.arg(type)
  if (any(probs < 0 | probs > 1))      stop("Probabilities must be between 0 and 1 inclusive")
  nams <- paste(format(round(probs * 100, if (length(probs) >
                                              1) 2 - log10(diff(range(probs))) else 2)), "%", sep = "")

  if(na.rm & any(is.na(weights))){   ###### new
    i<- is.na(weights)
    x <- x[!i]
    weights <- weights[!i]
  }
  i <- weights <= 0         # nwe: kill negative and zero weights and associated data
  if (any(i)) {
    x <- x[!i]
    weights <- weights[!i]
  }
  if (type == "quantile") {
    if(sum(weights) < 1000000 ) {weights<- weights*1000000/sum(weights)}  ##### new
    w <- wtd.table(x, weights, na.rm = na.rm, normwt = normwt,
                   type = "list")
    x <- w$x
    wts <- w$sum.of.weights
    n <- sum(wts)
    order <- 1 + (n - 1) * probs
    low <- pmax(floor(order), 1)
    high <- pmin(low + 1, n)
    order <- order%%1
    allq <- approx(cumsum(wts), x, xout = c(low, high), method = "constant",
                   f = 1, rule = 2)$y
    k <- length(probs)
    quantiles <- (1 - order) * allq[1:k] + order * allq[-(1:k)]
    names(quantiles) <- nams
    return(quantiles)
  }
  w <- wtd.Ecdf(x, weights, na.rm = na.rm, type = type, normwt = normwt)
  structure(approx(w$ecdf, w$x, xout = probs, rule = 2)$y,
            names = nams)
}




wtd.table<- function (x, weights = NULL, type = c("list", "table"), normwt = FALSE,
                      na.rm = TRUE) {
  # Function taken from HMISC, but issue solved which is documented here: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-429634634
  p_load(timeDate)
  type <- match.arg(type)
  if (!length(weights))
    weights <- rep(1, length(x))
  isdate <- ( class(x)[1]=="Date"  | class(x)[1]=="POSIXct") ### MODIFIED
  ax <- attributes(x)
  ax$names <- NULL
  if (is.character(x))
    x <- as.factor(x)
  lev <- levels(x)
  x <- unclass(x)
  if (na.rm) {
    s <- !is.na(x + weights)
    x <- x[s, drop = FALSE]
    weights <- weights[s]
  }
  n <- length(x)
  if (normwt)
    weights <- weights * length(x)/sum(weights)
  i <- order(x)
  x <- x[i]
  weights <- weights[i]
  if (anyDuplicated(x)) {
    weights <- tapply(weights, x, sum)
    if (length(lev)) {
      levused <- lev[sort(unique(x))]
      if ((length(weights) > length(levused)) && any(is.na(weights)))
        weights <- weights[!is.na(weights)]
      if (length(weights) != length(levused))
        stop("program logic error")
      names(weights) <- levused
    }
    if (!length(names(weights)))
      stop("program logic error")
    if (type == "table")
      return(weights)
    #x <-  all.is.numeric(names(weights), "vector")#  modified: commented out. function checked whether all are numeric and if yes returned the weights
    if (isdate)      attributes(x) <- c(attributes(x), ax)
    x_out<- as.numeric(names(weights))
    names(weights) <- NULL
    return(list(x = x_out, sum.of.weights = weights))
  }
  xx <- x
  if (isdate)
    attributes(xx) <- c(attributes(xx), ax)
  if (type == "list")
    list(x = if (length(lev)) lev[x] else xx, sum.of.weights = weights)
  else {
    names(weights) <- if (length(lev))
      lev[x]
    else xx
    weights
  }
}

wtd.mean <- function (x, weights = NULL, normwt = "ignored", na.rm = TRUE) {
  # Function taken from HMISC, but issue solved which is documented here: https://github.com/harrelfe/Hmisc/issues/97#issuecomment-429634634
  if (!length(weights))
    return(mean(x, na.rm = na.rm))
  if (na.rm) {
    s <- !is.na(x + weights)
    x <- x[s]
    weights <- weights[s]
  }
  sum(weights * x)/sum(weights)
}


```

# CPS Cleaning

I am using IPUMS CPS downloads (see codebook in data file where original download is kept). 

* Data set info:
* IPUMS CPS
* Time period: Bsic Monthly from 01-1990 to 12-2019

I only want observations which were included in the earner study - the outgoing groups. This should replicate the NBER MORG files, giving me a large n sample of the population.

I think that this code will just turn my raw files into a MORG data set. I will create a project specific markdown for my Qualifying Paper project.

# Today's Notebook

## (07-22-2021)

Going to try new format - Data Exploration! I will write notes and run things, and label my sections by date. Once I figure out what I am doing, I will move the final code to a new file.

# Previous Notebooks

## (07-22-2021)

Back to figuring out the CPS!



## (07-21-2021)

Goals for today:

* Import CPS csv's
  * read_csv is very slow!
  * I am going to use data.table instead: fread()
  * NOPE - I am going to use an SQLite database
* Extract only outgoing groups

### Notes on SQLite

Because the data file is so large, I decided to access it as an SQLite database, instead of loading it into memory.

Information on this is below.

*NOTE: In the future, when I understand SQL, I should rewrite the code, as I could more easily extract just the outgoing groups (which requires loading the database with "integer" columns) in SQL, and leave other stuff to R. For now, I will be doing it in dplyr.

### Summary of 07-21

Okay, it was a frustrating day, but I got a lot done!

I set up a very cool SQLite thing so that I can use big-ish data sets!

I need to figure out how to turn the monthly basic data I have into statistics. Don't forget - each month is its own survey! So the weights equal up to the total population.

Also, groups are often interviewed in more than one year. 

I may need the "MISH" variable (the month the household was in) so I can get the ORG months - they are surveyed for the earner survey on Month 4 and 8 (MISH = 4 | 8)


# SQLite

## SQLite Code

### Create Database

*!!! NOTE: Instead of using the below coding method (which imported every column as TEXT), I used "DB Browser for SQLite" which is on my computer, and did a good job of sorting between INTEGER and TEXT*

*I DID NOT use the following code* 

Because loading the entire file into RAM is unwieldy, I am going to create an SQLite database, and draw from that.

See: https://data.library.virginia.edu/creating-a-sqlite-database-for-use-with-r/

I am going to write the code that I use here for reference.

However, I am entering it in a command line utiilty located at: "C:\Users\Sam\Desktop\sqlite-tools-win32-x86-3360000\sqlite-tools-win32-x86-3360000"

CODE:

.cd 'C:\Users\Sam\OneDrive - Cuny GradCenter\CUNY! (Cloud)\R\CPS_Master\CPS_Master\data\IPUMS_CPS'

.open cps_master.db

.mode csv

.import IPUMS_CPS_ALL_07-2021.csv cpsALL

.schema
*NOTE: I used .schema to make sure my columns were imported with good formats*
Dang, it imported everything as TEXT. Well, I can just change it later with dplyr. The procedure for changing in SQLite seems tedious (details at: https://data.library.virginia.edu/creating-a-sqlite-database-for-use-with-r/)

## RSQLite Code

```{r eval=TRUE}

# This code establishes a connection with my database
# See: https://data.library.virginia.edu/creating-a-sqlite-database-for-use-with-r/

con <- dbConnect(RSQLite::SQLite(), here("data/IPUMS_CPS/cps_master.db"))

# This allows dplyr to use the connection like an object:

cpsALL <- tbl(con, "cpsALL")

```

# Disconnect SQLite

Run this code to disconnect from the database

```{r eval=FALSE}

dbDisconnect(con)

```

# Previous Experiments

## Query and Save

Now that I have a SQLite database, I can extract only the data I need, create a grouped table of industries, which will be a much smaller file, and save that as a csv.

### Filter rows

I just want observations which are from the outgoing rotation groups.

```{r eval=FALSE}

# NOTE: I thought that filter() for just non-zero EARNWT would give me what I wanted, but it seems like no? Another way is to use MISH (month of survey for that household) and just use months 4 and 8, but I don't have that variable, so I will need to do another massive download!

cpsORG <- cpsALL %>% 
  filter(YEAR >= 2003)

```

### Creating Grouped Panel

I am creating a panel data set, where each row is an Industry-Year. This means I will be grouping and summarizing the CPS data, and I need to pick the variables that I wish to include.

#### Test

I am going to create employment counts as a test. This means adding up the EARNWT for each industry-year.

```{r eval=FALSE}

# NOTE: I am grouping by IND so I can compare with unionstats - for the real project I will be grouping by IND1990

cpsGROUP <- group_by(cpsORG, IND, YEAR, MONTH)
cpsTEST <- summarise(cpsGROUP,
          TotEMP = sum(WTFINL, na.rm = TRUE)) %>% 
  collect()
cpsTEST <- summarise(cpsTEST,
                     avgEMP = mean(TotEMP)) %>% 
  collect()

```



# Exploratory Notebook

# (07-24-2021)

I start by trying to figure out if I need to use a different kind of weighting with my industry coding, since it is not necessarily part of the outgoing earner study. The issue is, with the outgoing group, there is only one (I thinkg) observation per person per year. But there is an industry question every month... If industry is part of the basic, then I guess it should be weighted like a basic question?

I need to see if there are zeroes for EARNWT or what the deal is.

ELIGORG !!! It is an ORG eligibility flag! I don't need MISH ! https://cps.ipums.org/cps-action/variables/ELIGORG#description_section

## ELIGORG filter

I just want observations which are from the outgoing rotation groups.

```{r eval=FALSE}

# NOTE: Unlike other version of this above, here I am using ELIGORG !

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003)

```

Now I'll try this again...

```{r eval=FALSE}

# NOTE: I am grouping by IND so I can compare with unionstats - for the real project I will be grouping by IND1990

cpsGROUP <- group_by(cpsORG, IND, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12)) %>% 
  collect()

```

It worked!!!! I AM INVINCIBLE!!!!!!

(I am getting the same numbers as unionstats)

Now I will add (see above) the union info, and verify with unionstats, just to make sure it is working.

```{r eval=FALSE}

# NOTE: Unlike other version of this above, here I am using ELIGORG !

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0))

view(head(cpsORG, 100))

```

Looks good!

```{r eval=FALSE}

# NOTE: I am grouping by IND so I can compare with unionstats - for the real project I will be grouping by IND1990

cpsGROUP <- group_by(cpsORG, IND, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12)) %>% 
                       collect()

```

WORKED AGAIN!!!!

Okay, now I am going to use IPUMS ind1990 variable instead! I won't be able to confirm it with unionstats, because it is defined differently.

```{r eval=FALSE}

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0))

cpsGROUP <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12)) %>% 
                       collect()


```

NOTE: Should I just go ahead and use all the years' data? I have this nice ind1990 variable? Let me export this, and see.

```{r eval=FALSE}

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0))

cpsGROUP <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12)) %>% 
                       collect()

write_csv(cpsTEST, "cpsTEST_07-24.csv")

```

I am analyzing with pivot table to see if there are significant breaks in the employment data.

Okay - pivot table showed a lot of goofy stuff going on in 2003 - so let's start there instead!

### Final Version

Final version going forward:

```{r eval=FALSE}

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0))

cpsGROUP <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12)) %>% 
                       collect()


```

## Creating Variables

1. Unionization Rate
2. Manager Ratio
3. (Others in future)

### unionization rate

```{r eval=FALSE}

cpsDATA <- cpsTEST %>% 
  mutate(pctUNION = (unionEMP / TotEMP)*100)


```

seems to have worked!

### Manager Ratio

I need to decide which occ codes to use. 

IPUMS occ2010: https://cps.ipums.org/cps-action/variables/OCC2010#codes_section

I am going to create 2 variables - one with both managers and supervisors, one with just managers.

First, I need to take a look at the coding on the CPS:

```{r eval=FALSE}

view(head(cpsORG, 100))

```

occ2010 (along with all other codes) were converted to numeric - which is convenient now, but may mess me up later...

For now, let's just take the number of top managers:

0010 - Chief executives and legislators/public administration
...
0430 - Managers, nec (including Postmasters)

```{r eval=FALSE}

# Create ORG Microdata

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0),
         manager = if_else(OCC2010 >= 10 & OCC2010 <= 430, 1, 0))

# view(head(cpsORG, 100))

# Create Industry Panel

cpsGROUP <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12),
                     mgmtEMP = (sum(EARNWT * manager, na.rm = TRUE)/12)) %>% 
                       collect()

# Create New Variables

cpsDATA <- cpsTEST %>% 
  mutate(pctUNION = (unionEMP / TotEMP)*100,
         mgmtRATIO = (mgmtEMP / TotEMP)*100)


```

## Hourly Wages

Going off EPI advice: https://www.epi.org/data/methodology/

They use:

* Hourly workers: Hourly wage (HOURWAGE)
* Salary workers: weekly wage / hours worked
  = EARNWEEK / UHRSWORKORG
  filter: PAIDHOUR == 1 - this means that the worker is NOT paid by the hour
  
### hrWAGE2

If PAIDHOUR = 2, they are hourly, so use the HOURWAGE
If PAIDHOUR = 1, they are not hourly, so use EARNWEEK / UHRSWORKORG (NOPE! see note below, I must use UHRSWORK1)

SET TO MISSING:

HOURWAGE - 999.99 = NIU (not in universe)

UHRSWORKORG - 999 = NIU, 998 = Don't Know

#### NOTE! UHRSWORK1

*NOTE* For the Earner study, salary workers are not asked usual hours (UHRSWORKORG). Instead, I will be using the Basic question: "Hours usually worked per week at main job" (UHRSWORK1). I should double check that this is what EPI and others do.

#### hrWAGE2 code

```{r eval=FALSE}

# Create ORG Microdata

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0),
         manager = if_else(OCC2010 >= 10 & OCC2010 <= 430, 1, 0),
         HOURWAGE2 = if_else(HOURWAGE != 999.99, HOURWAGE, NA_integer_),
         hrWAGE2 = if_else(PAIDHOUR == 2, HOURWAGE2,
                           if_else(PAIDHOUR == 1, (EARNWEEK / UHRSWORK1), NA_integer_))
         )

## view(head(cpsORG, 300))


# Another way to check:

## cpsCHECK <- slice_sample(cpsORG, n = 100) %>% collect()

# Checking on the WKSWORKORG variable - since my "head" has a lot of "1" weeks worked...

## wksCOUNT <- cpsORG %>% count(WKSWORKORG) %>% collect()

# NOTE: Looks like it's all good - most people either work 52 weeks a year, or are 0 (not in universe)
  

# Create Industry Panel

cpsGROUP <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12),
                     mgmtEMP = (sum(EARNWT * manager, na.rm = TRUE)/12)) %>% 
                       collect()

# Create New Variables

cpsDATA <- cpsTEST %>% 
  mutate(pctUNION = (unionEMP / TotEMP)*100,
         mgmtRATIO = (mgmtEMP / TotEMP)*100)

```




## ! Leave out industries!

* Don't forget to leave out certain industries! Like Real Estate!

# (07-25-2021)

# Incomes - weighted means

I need to get some income variables

- As a test, I should just do the average hourly income per industry - even though I probably won't use it.

*NOTE* Adding code to make UHRSWORK1 missing:

000 - 0 hours
997 - hours vary
999 - NIU/Missing

*NOTE* I am going to start pulling down

## More variables

Now that I have average wage, I'm going to try some others...

Manager wage - just wages of managers
Nonsup wage - just non-managers

And some more!

log of wage variables
...
*variance* of log wage - this is how Kristal et al (2017) measures wage inequality in an industry -- *ACTUALLY* looks like maybe they just use variance for the whole economy, and use 90/10 gap for industries.

```{r eval=FALSE}

# Create ORG Microdata

# list of variables:

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0),
         manager = if_else(OCC2010 >= 10 & OCC2010 <= 430, 1, 0),
         HOURWAGE2 = if_else(HOURWAGE != 999.99, HOURWAGE, NA_integer_),
         UHRSWORK1_2 = if_else(UHRSWORK1 == 999 | UHRSWORK1 == 997 | UHRSWORK1 == 0, NA_integer_, UHRSWORK1),
         hrWAGE2 = if_else(PAIDHOUR == 2, HOURWAGE2,
                           if_else(PAIDHOUR == 1, (EARNWEEK / UHRSWORK1_2), NA_integer_)),
         mgmtWAGE = if_else(manager == 1, hrWAGE2, NA_integer_),
         NONmgmtWAGE = if_else(manager == 0, hrWAGE2, NA_integer_),
         ln_hrWAGE2 = log(hrWAGE2),
         ln_mgmtWAGE = log(mgmtWAGE),
         ln_NONmgmtWAGE = log(NONmgmtWAGE)
         ) %>% 
  select(ELIGORG, YEAR, unionMEM, manager, HOURWAGE2, UHRSWORK1_2, hrWAGE2, PAIDHOUR, IND1990, OCC2010, EARNWT, mgmtWAGE, NONmgmtWAGE, ln_hrWAGE2, ln_mgmtWAGE, ln_NONmgmtWAGE) %>% 
  collect()

## view(head(cpsORG, 300))


# Another way to check:

## cpsCHECK <- slice_sample(cpsORG, n = 100) %>% collect()

# Checking on the WKSWORKORG variable - since my "head" has a lot of "1" weeks worked...

## wksCOUNT <- cpsORG %>% count(WKSWORKORG) %>% collect()

# NOTE: Looks like it's all good - most people either work 52 weeks a year, or are 0 (not in universe)
  

# Create Industry Panel

cpsGROUP <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsGROUP, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12),
                     mgmtEMP = (sum(EARNWT * manager, na.rm = TRUE)/12), 
                     avgWAGE = weighted.mean(hrWAGE2, EARNWT, na.rm = TRUE),
                     NONmgmtAVG = weighted.mean(NONmgmtWAGE, EARNWT, na.rm = TRUE),
                     mgmtAVG = weighted.mean(mgmtWAGE, EARNWT, na.rm = TRUE),
                     ln_avgWAGE = weighted.mean(ln_hrWAGE2, EARNWT, na.rm = TRUE),
                     ln_NONmgmtAVG = weighted.mean(ln_NONmgmtWAGE, EARNWT, na.rm = TRUE),
                     ln_mgmtAVG = weighted.mean(ln_mgmtWAGE, EARNWT, na.rm = TRUE),
                     var_wages = wtd.var(ln_hrWAGE2, EARNWT, na.rm = TRUE))

# Create New Variables

cpsDATA <- cpsTEST %>% 
  mutate(pctUNION = (unionEMP / TotEMP)*100,
         mgmtRATIO = (mgmtEMP / TotEMP)*100)

```

### Quantiles - 90/10

Seems like Kristal 2017 uses 90/10 ratio as measure of inequality

WARNING: EPI argue that you need to bin before using quantiles, since wages clump at certain values: https://www.epi.org/data/methodology/ (see "Wage Percentiles" section)

```{r eval=FALSE}

# Create ORG Microdata

# list of variables:

cpsORG <- cpsALL %>% 
  filter(ELIGORG == 1 & YEAR >= 2003) %>% 
  mutate(unionMEM = if_else(UNION == 2, 1, 0),
         manager = if_else(OCC2010 >= 10 & OCC2010 <= 430, 1, 0),
         HOURWAGE2 = if_else(HOURWAGE != 999.99, HOURWAGE, NA_integer_),
         UHRSWORK1_2 = if_else(UHRSWORK1 == 999 | UHRSWORK1 == 997 | UHRSWORK1 == 0, NA_integer_, UHRSWORK1),
         hrWAGE2 = if_else(PAIDHOUR == 2, HOURWAGE2,
                           if_else(PAIDHOUR == 1, (EARNWEEK / UHRSWORK1_2), NA_integer_)),
         mgmtWAGE = if_else(manager == 1, hrWAGE2, NA_integer_),
         NONmgmtWAGE = if_else(manager == 0, hrWAGE2, NA_integer_),
         ln_hrWAGE2 = log(hrWAGE2),
         ln_mgmtWAGE = log(mgmtWAGE),
         ln_NONmgmtWAGE = log(NONmgmtWAGE)
         ) %>% 
  select(ELIGORG, YEAR, unionMEM, manager, HOURWAGE2, UHRSWORK1_2, hrWAGE2, PAIDHOUR, IND1990, OCC2010, EARNWT, mgmtWAGE, NONmgmtWAGE, ln_hrWAGE2, ln_mgmtWAGE, ln_NONmgmtWAGE) %>% 
  collect()

## view(head(cpsORG, 300))


# Another way to check:

## cpsCHECK <- slice_sample(cpsORG, n = 100) %>% collect()

# Checking on the WKSWORKORG variable - since my "head" has a lot of "1" weeks worked...

## wksCOUNT <- cpsORG %>% count(WKSWORKORG) %>% collect()

# NOTE: Looks like it's all good - most people either work 52 weeks a year, or are 0 (not in universe)
  

# Create Industry Panel

cpsTEST <- group_by(cpsORG, IND1990, YEAR)

cpsTEST <- summarise(cpsTEST, 
                     TotEMP = (sum(EARNWT, na.rm = TRUE)/12),
                     unionEMP = (sum(EARNWT * unionMEM, na.rm = TRUE)/12),
                     mgmtEMP = (sum(EARNWT * manager, na.rm = TRUE)/12), 
                     avgWAGE = weighted.mean(hrWAGE2, EARNWT, na.rm = TRUE),
                     NONmgmtAVG = weighted.mean(NONmgmtWAGE, EARNWT, na.rm = TRUE),
                     mgmtAVG = weighted.mean(mgmtWAGE, EARNWT, na.rm = TRUE),
                     ln_avgWAGE = weighted.mean(ln_hrWAGE2, EARNWT, na.rm = TRUE),
                     ln_NONmgmtAVG = weighted.mean(ln_NONmgmtWAGE, EARNWT, na.rm = TRUE),
                     ln_mgmtAVG = weighted.mean(ln_mgmtWAGE, EARNWT, na.rm = TRUE),
                     var_wages = wtd.var(ln_hrWAGE2, EARNWT, na.rm = TRUE),
                     Wage90 = wtd.quantile(hrWAGE2, EARNWT, probs = .9, na.rm = TRUE),
                     Wage10 = wtd.quantile(hrWAGE2, EARNWT, probs = .1, na.rm = TRUE))

# Drop big ole data set

rm(cpsORG)

# Create New Variables

cpsDATA <- cpsTEST %>% 
  mutate(pctUNION = (unionEMP / TotEMP)*100,
         mgmtRATIO = (mgmtEMP / TotEMP)*100,
         ratio90_10 = (Wage90 / Wage10),
         log90_10 = log(Wage90 / Wage10))

```

## Notes

Things seem to be working okay? Go back over everything.

Next, I think you can start running models?

# (07-26-2021)

## College supply

Count up those with BA+, divide by total

Other ideas:
- Women
- Non-white?

ACTUALLY - I'm ready to move things to a new file - where I will run models

